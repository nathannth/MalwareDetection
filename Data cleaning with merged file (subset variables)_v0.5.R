pacman::p_load(mice, dplyr, tibble, tidyr, stringr, lubridate, VIM, urltools, superml, 
               finalfit, ggplot2)

#Remember your wd to where ever you have your datasets 
setwd("C:/Users/natha/Others")
setwd("C:/Users/peng_/Desktop/EBA")

#Read in main dataset
malware = read.csv('Full_20200914.csv', na.strings = c("", " "))

#Check if the column name appears as analysis_start_time properly on your machine.
#If not, rename it.
malware = malware %>% rename(analysis_start_time = ï..analysis_start_time)

# Select useful variables to keep and drop the rest
malware_columns = c("threat_level", "threat_level_human", "threat_score", "url_analysis",
                    "av_detect", "size", "tags", "type", "extracted_files", "ssdeep",
                    "domains", "et_alerts", "et_alerts_real_total", "et_alerts_total",
                    "hosts_geolocation", "vx_family", "job_id", "analysis_start_time", "sha256",
                    "processes", "environment_description", "environment_id", "submit_name")

malware.subset = malware %>% select(all_of(malware_columns))

##### Removing Duplicates #####
#Keep only distinct job_id entries, remove the duplicates
mal.dist = malware.subset %>% distinct(job_id, .keep_all = TRUE)
#summary(mal.dist)

##### Mapping additional fields #####

#Reading in additional fields csv
df = read.csv("Summary_20200914.csv", na.strings = c("", " "))

#Check if your machine reads in the column names properly. The column names may 
#appear as ï..job_id instead of just job_id. If so, rename the column name.
df = df %>% rename(job_id = ï..job_id)
df.dist = df %>% distinct(job_id, .keep_all = TRUE)

#summary(df.dist)

#Cleaning up unused dataframe since we won't need it anymore.
rm("df")

#Generating columns to merge. Only select useful variables.
columns_to_merge = c("job_id", "certificates", "classification_tags", "file_metadata.file_analysis", 
                     "file_metadata.file_compositions", "file_metadata.imported_objects",
                     "file_metadata.total_file_compositions_imports", "imphash", "mitre_attcks", "sha512",
                     "total_network_connections", "total_processes", "total_signatures", "type_short", "verdict")

#Using left join to only join additional columns
df.dist = df.dist %>%
  select(all_of(columns_to_merge))

mal.dist <- left_join(mal.dist, df.dist, by = "job_id")

#Cleaning up unused dataframe since we won't need it anymore.
rm("df.dist")

##### Mapping entropy data #####

#Reading in entropy csv
entropy <- read.csv("entropy-clean.csv", na.strings = c("", " "))

#Choosing useful entropy columns to keep based on domain knowledge as well as EDA observations
entropy_columns <- c(".bss", ".data", ".idata", ".rsrc", ".text", ".tls", "sha256")

entropy = entropy %>% select(all_of(entropy_columns))

#Using left join to only join additional columns
mal.dist <- left_join(mal.dist, entropy, by = "sha256")

#Cleaning up unused dataframe since we won't need it anymore.
rm("entropy")


##### The following code adds in the current MAST performance metrics in another column

# Function to assign the current performance metric. Logic is as follow:
# If 0, map to 0 (benign), if av_detect is 1, map to 1 (suspicious), if 2 or more
# detection, map to 2 (malicious). Otherwise, it will be NA, map to unknown (3).

# For APM
# mast_result <- function(av_detect){
#   if (is.na(av_detect)){
#     x <- 3
#   } else if (av_detect==0){
#     x <- 0
#   } else if (av_detect==1){
#     x <- 1
#   } else x <- 2
#   
#   return (x)
# }

# Function to new column to indicate the action, whether to block threats or not
# If benign, won't block. Otherwise, will block if suspicious, malicious or unknown.
block_threat_func <- function(threat_score){
  if(threat_score==0){
    result <- 0
  } else
    result <- 1
  
  return (result)
}

# Apply the mapping function and add in additional column for MAST current performance metric
# For APM
# mal.dist$mast <- mapply(mast_result, mal.dist$av_detect)
# summary(mal.dist$mast)

# Create new column, block_threat.
mal.dist$block_threat <- mapply(block_threat_func, mal.dist$threat_score)

# For APM
# mal.dist$mast_block_threat <- mapply(block_threat_func, mal.dist$mast)

### Creating additional features:
# 1. Length of the submit_name, which could be filename length or URL length
# Aim is to explore if there's any correlation between length of URL/filename with
# the maliciousness

mal.dist$name.length = mapply(nchar, mal.dist$submit_name)




##### Conversions of column datatypes #####

#Converting columns to factors
cols <- c("threat_level_human", "url_analysis","threat_level", "environment_description", 
          "environment_id", "verdict", "block_threat")
mal.dist[cols] <- lapply(mal.dist[cols], factor)
str(mal.dist)
summary(mal.dist)

# Save a copy of the distinct data into CSV
write.csv(mal.dist,"Subset_Distinct_BAP.csv", row.names = FALSE)

######################################################################

# Checking the NAs


summary(mal.dist)

# There are a few variables whereby majority of the values are NAs, e.g. 44432 NAs 
# out of 46666 observations. These will be dropped. Other variables not used for 
# prediction, e.g. threat_level_human which is essentially a dictionary to threat_level
# will also be dropped. There are some variables which are repeats of other variables and
# these will be dropped too. Only select the useful columns.

drop_column <- c("verdict", "type_short","sha512", "imphash", 
                 "file_metadata.total_file_compositions_imports", "file_metadata.imported_objects",
                 "file_metadata.file_compositions", "file_metadata.file_analysis", "certificates",
                 "environment_description", "sha256", "analysis_start_time", "job_id", "vx_family",
                 "et_alerts_total", "et_alerts_real_total", "et_alerts", "ssdeep", "extracted_files",
                 "tags", "threat_level_human", "av_detect")


mal.dist <- select (mal.dist, -all_of(drop_column))

summary(mal.dist)

mal.dist %>% missing_plot(title="Missing Values (Whole Dataset) - Initial")

# From the plot, it appears that there are some records whereby multiple variables for the
# whole record are missing. This is a small percentage, 5,510 out of 46,666. These records will
# be removed.

mal.dist <- mal.dist %>% drop_na("total_network_connections")
summary(mal.dist)
mal.dist %>% missing_plot(title="Missing Values (Whole Dataset) - Dropped")


# From the plot, there appears to be many records with missing data as well. However, there
# is a need to separate the dataset into files and URLs as some variables are only applicable
# for certain types. Before splitting, we will perform the feature engineering (creation of
# additional variables) first to avoid duplicating for each set.


# The following code does:
# Extract URL suffix, domain and file extension from submit_name
# Extract country name from host_geolocation

# submit_name (we can extract out domain name.
# Started with URL.info, we can append this to the main dataframe as feature engineering)

URLs <- filter(mal.dist, url_analysis == "True")$submit_name

URL.info <- suffix_extract(domain(URLs))

#this will convert, for example, com.sg to com, or blogspot.com to com
clean.suffix = case_when(
  str_detect(URL.info$suffix, "\\.?com\\.?") ~ "com",
  str_detect(URL.info$suffix, "\\.?net\\.?") ~ "net",
  str_detect(URL.info$suffix, "\\.?gov\\.?") ~ "gov",
  str_detect(URL.info$suffix, "\\.?edu\\.?") ~ "edu",
  str_detect(URL.info$suffix, "\\.?org\\.?") ~ "org",
  str_detect(URL.info$suffix, "\\.?co\\.?") ~ "co",
  TRUE ~ URL.info$suffix
)

#Merging URL Suffix and domain, as well as file extension to main dataframe.

mal.dist = mal.dist %>%
  mutate(file.extension = if_else(mal.dist$url_analysis == "False", str_extract(mal.dist$submit_name, "[^.]+$"), ""),
         url.suffix = ifelse(mal.dist$url_analysis == "True", clean.suffix ,""),
         url.domain = ifelse(mal.dist$url_analysis == "True", URL.info$domain ,""))

as.data.frame(head(sort(table(mal.dist$url.domain), decreasing = TRUE ), 10))[2:10,]
as.data.frame(head(sort(table(mal.dist$url.suffix), decreasing = TRUE ), 10))
as.data.frame(head(sort(table(mal.dist$file.extension), decreasing = TRUE ), 10))[2:10,]


# hosts_geolocation (extract country names)
mal.dist$hosts_geolocation = str_extract(mal.dist$hosts_geolocation, "[:upper:]{3}")

table(mal.dist$hosts_geolocation)


# The following code performs cleaning on the text data and removing stop words

# Creating the stopwords (the headers within the data) so as to only keep the content
stopwords <- c(paste0("'tactic':|'technique':|'attck_id':|'attck_id_wiki':|",
                      "'https://attack.mitre.org/techniques/|'malicious_identifiers_count':|",
                      "'malicious_identifiers':|'suspicious_identifiers_count':|",
                      "'suspicious_identifiers':|'informative_identifiers_count':|",
                      "'informative_identifiers':|'command_line':|'normalized_path':|",
                      "'name':|'uid':|'sha256':"))

# Remove stopwords from the fields with text data to prepare for text analytics
mal.dist$processes = mal.dist$processes %>% str_remove_all(stopwords)
mal.dist$classification_tags = mal.dist$classification_tags %>% str_remove_all(stopwords)
mal.dist$mitre_attcks = mal.dist$mitre_attcks %>% str_remove_all(stopwords)
mal.dist$type = mal.dist$type %>% str_remove_all(stopwords)

# Remove punctuation 
mal.dist$processes <- sapply(mal.dist$processes, 
                             function(x){gsub(pattern = "[[:punct:]]",
                                         replacement = " ", x)})
mal.dist$classification_tags <- sapply(mal.dist$classification_tags, 
                             function(x){gsub(pattern = "[[:punct:]]",
                                              replacement = " ", x)})
mal.dist$mitre_attcks <- sapply(mal.dist$mitre_attcks, 
                             function(x){gsub(pattern = "[[:punct:]]",
                                              replacement = " ", x)})
mal.dist$type <- sapply(mal.dist$type, 
                             function(x){gsub(pattern = "[[:punct:]]",
                                              replacement = " ", x)})


# Convert the text to lower case. Punctuations are left inside so that ' can be used as separator
text_cols <- c("processes","classification_tags","mitre_attcks", "type")
mal.dist[text_cols] <- lapply(mal.dist[text_cols], tolower)


write.csv(mal.dist,"Subset_Distinct_Cleaned.csv", row.names = FALSE)

##################################################################################

##### Basic EDA to identify logical groups of data

# Identify the proportion of url and file analysis demands
ggplot(data=mal.dist, aes(x=url_analysis, fill=url_analysis))+geom_bar()+
  ggtitle("URL / File Distribution")

# Create subsets, differentiating records for file analysis and URL analysis
mal.dist.files <- filter(mal.dist, mal.dist$url_analysis=="False")
mal.dist.urls <- filter(mal.dist, mal.dist$url_analysis=="True")


# ggplot(data=mal.dist, aes(x=file.extension, fill=file.extension))+geom_bar()+
#   ggtitle("File Extensions")

# Identify for files, any particular file types to focus on or separate out as a group
file.ext <- mal.dist.files %>%
  count(file.extension) %>%
  top_n(8) %>%
  arrange(n, file.extension) %>%
  mutate(file.extension = factor(file.extension, levels = unique(file.extension)))

mal.dist %>%
  filter(file.extension %in% file.ext$file.extension) %>%
  mutate(file.extension = factor(file.extension, levels = levels(file.ext$file.extension))) %>%
  ggplot(aes(x = file.extension, fill = file.extension)) +
  labs(title = "Top 8 File Types") +
  geom_bar()


##################################################################################



# After the creation of additional features, we will proceed to seggregate the
# records into 3 categories: URL, EXE and Non-EXE files.



# For records for file analysis, further segregate into analysis for executable
# and those for non executable files. Some of the variables are only applicable for
# executable file types.
mal.dist.files.exe <- filter(mal.dist.files, grepl('executable', type))
mal.dist.files.nonexe <- filter(mal.dist.files, !grepl('executable', type))



# For each category, drop those columns which are not relevant or has many missing

summary(mal.dist.urls)
url_drop_col <- c("size",".bss",".data", ".idata", ".rsrc", ".text", ".tls", "type")
mal.dist.urls <- select (mal.dist.urls, -all_of(url_drop_col))
mal.dist.urls %>% missing_plot(title = "Missing Values (URL)")

summary(mal.dist.files.exe)
mal.dist.files.exe %>% missing_plot()
exe_drop_col <- c("domains", "hosts_geolocation","url.suffix","url.domain")
mal.dist.files.exe <- select (mal.dist.files.exe, -all_of(exe_drop_col))
mal.dist.files.exe %>% missing_plot(title = "Missing Values (EXE)")

# Less missing values. Imputation to be performed for some of the executable file
# section header subsequently.

# For non-exe, need to remove executable file section header info in addition to 
# fields removed for exe files.
summary(mal.dist.files.nonexe)
mal.dist.files.nonexe %>% missing_plot()
nonexe_drop_col <- c("domains", "hosts_geolocation","url.suffix","url.domain", 
                 ".bss",".data", ".idata", ".rsrc", ".text", ".tls")
mal.dist.files.nonexe <- select (mal.dist.files.nonexe, -all_of(nonexe_drop_col))
mal.dist.files.nonexe %>% missing_plot(title = "Missing Values (Non-EXE)")

##################################################################################

# Plot the NA values in each category to see if it's MAR or MCAR etc.

mal.dist.files.exe %>% missing_plot()
mal.dist.files.nonexe %>% missing_plot()
mal.dist.urls %>% missing_plot()

##################################################################################
#Check for outliers in all: size, total_network_connection, total_processes,
#total signatures. Section headers are already in 0-8 range, so no outliers.

#1. Exe
#size
ggplot(mal.dist.files.exe, aes(size)) + geom_histogram() + 
  ggtitle("Exe Size")

ggplot(mal.dist.files.exe, aes(log((size)))) + geom_histogram() +
  ggtitle("Exe Size (Log Transformation)")

mal.dist.files.exe$size_log = log(mal.dist.files.exe$size)

# Tyring to cap the size. Not a good idea.
qnt <- quantile(mal.dist.files.exe$size, probs=c(.25, .75), na.rm = T)
cap <- quantile(mal.dist.files.exe$size, probs=c(.05, .95), na.rm = T)
Th <- 1.5 * IQR(mal.dist.files.exe$size, na.rm = T)
mal.dist.files.exe$cap_size <- 0
mal.dist.files.exe$cap_size <- ifelse((mal.dist.files.exe$size < (qnt[1] - Th)), cap[1], mal.dist.files.exe$size)
mal.dist.files.exe$cap_size <- ifelse((mal.dist.files.exe$size > (qnt[2] + Th)), cap[2], mal.dist.files.exe$size)

ggplot(mal.dist.files.exe, aes(cap_size)) + geom_histogram() + 
  ggtitle("Exe Size (Capped)")

# Not good, so will remove the column
mal.dist.files.exe$cap_size <- NULL

# Total network connection
ggplot(mal.dist.files.exe, aes(total_network_connections)) + geom_histogram() + 
  ggtitle("Exe Total Network Connections")

table(mal.dist.files.exe$total_network_connections)

summary(mal.dist.files.exe$total_network_connections)

outliers.exe.network <- filter(mal.dist.files.exe, (abs(total_network_connections - median(total_network_connections)) > 2*sd(total_network_connections)))
outliers.exe.network$total_network_connections
# There are only 3 outliers, we can remove them.

mal.dist.files.exe <- filter(mal.dist.files.exe, !(abs(total_network_connections - median(total_network_connections)) > 2*sd(total_network_connections)))

ggplot(mal.dist.files.exe, aes(total_network_connections)) + geom_histogram() + 
  ggtitle("Exe Total Network Connections")


# Total_processes
ggplot(mal.dist.files.exe, aes(total_processes)) + geom_histogram() + 
  ggtitle("Exe Total Processes")

ggplot(mal.dist.files.exe, aes(sqrt(total_processes))) + geom_histogram() + 
  ggtitle("Exe Total Processes (Sqrt Transformation)")
#can't use Log, since there are a lot of 0's

mal.dist.files.exe$sqrt_total_processes <- sqrt(mal.dist.files.exe$total_processes)

#####Total Signatures
ggplot(mal.dist.files.exe, aes(total_signatures)) + geom_histogram() + 
  ggtitle("Exe Total Signatures")

outliers.exe.signatures <- filter(mal.dist.files.exe, (abs(total_signatures - median(total_signatures)) > 2*sd(total_signatures)))
nrow(outliers.exe.signatures)
#there are 330 outliers, we cannot remove them. Apply sqrt transformation.

ggplot(mal.dist.files.exe, aes(sqrt(total_signatures))) + geom_histogram() + 
  ggtitle("Exe Total Signatures (Sqrt Transformation)")

mal.dist.files.exe$sqrt_total_signatures <- sqrt(mal.dist.files.exe$total_signatures)

#########

#2. nonexe
#size
ggplot(mal.dist.files.nonexe, aes(size)) + geom_histogram() + 
  ggtitle("Non-Exe Size")

ggplot(mal.dist.files.nonexe, aes(log((size)))) + geom_histogram() +
  ggtitle("Non-Exe Size (Log Transformation)")

mal.dist.files.nonexe$size_log <- log(mal.dist.files.nonexe$size)

####total network connection
ggplot(mal.dist.files.nonexe, aes(total_network_connections)) + geom_histogram() + 
  ggtitle("Non-Exe Total Network Connections")

table(mal.dist.files.nonexe$total_network_connections)

outliers.nonexe.network <- filter(mal.dist.files.nonexe, (abs(total_network_connections - median(total_network_connections)) > 2*sd(total_network_connections)))
nrow(outliers.nonexe.network)
#there are 174 outliers, we cannot remove them. Apply sqrt.

ggplot(mal.dist.files.nonexe, aes(sqrt(total_network_connections))) + geom_histogram() + 
  ggtitle("Non-Exe Total Network Connections (Sqrt Transformation")

mal.dist.files.nonexe$sqrt_total_network_connections <- sqrt(mal.dist.files.nonexe$total_network_connections)

####total_processes
ggplot(mal.dist.files.nonexe, aes(total_processes)) + geom_histogram() + 
  ggtitle("Non-Exe Total Processes")

table(mal.dist.files.nonexe$total_processes)

ggplot(mal.dist.files.exe, aes(sqrt(total_processes))) + geom_histogram() + 
  ggtitle("Exe Total Processes (Sqrt Transformation)")
#can't use Log, since there are a lot of 0's

mal.dist.files.nonexe$sqrt_total_processes <- sqrt(mal.dist.files.nonexe$total_processes)

#####Total Signatures
ggplot(mal.dist.files.nonexe, aes(total_signatures)) + geom_histogram() + 
  ggtitle("Non-Exe Total Signatures")

ggplot(mal.dist.files.nonexe, aes(sqrt(total_signatures))) + geom_histogram() + 
  ggtitle("Non-Exe Total Signatures (Sqrt Transformation)")

mal.dist.files.nonexe$sqrt_total_signatures = sqrt(mal.dist.files.nonexe$total_signatures)

#####
#3. URLs

####total network connection
ggplot(mal.dist.urls, aes(total_network_connections)) + geom_histogram() + 
  ggtitle("URL Total Network Connections")

table(mal.dist.urls$total_network_connections)

ggplot(mal.dist.urls, aes(sqrt(total_network_connections))) + geom_histogram() + 
  ggtitle("URL Total Network Connections (Sqrt Transformation)")

mal.dist.urls$sqrt_total_network_connections <- sqrt(mal.dist.urls$total_network_connections)

####total_processes
ggplot(mal.dist.urls, aes(total_processes)) + geom_histogram() + 
  ggtitle("URL Total Processes")

table(mal.dist.urls$total_processes)

ggplot(mal.dist.urls, aes(sqrt(total_processes))) + geom_histogram() + 
  ggtitle("URL Total Processes (Sqrt Transformation)")
#can't use Log, since there are a lot of 0's

table(sqrt(mal.dist.urls$total_processes))
#after sqrt, the range is only 0 - 3.74. Hence, no outlier.

mal.dist.urls$sqrt_total_processes = sqrt(mal.dist.urls$total_processes)

#####Total Signatures
ggplot(mal.dist.urls, aes(total_signatures)) + geom_histogram() + 
  ggtitle("URL Total Signatures")

table(mal.dist.urls$total_signatures)

ggplot(mal.dist.files.nonexe, aes(sqrt(total_signatures))) + geom_histogram() + 
  ggtitle("URL Total Signatures (Sqrt Transformation)")

mal.dist.urls$sqrt_total_signatures <- sqrt(mal.dist.urls$total_signatures)

################################################################################

# Relationship between the variables and threat level. 
# Interesting observations will be included in presentation slides

# EXE
ggplot(data=mal.dist.files.exe, aes(x=threat_level, y=total_signatures, fill=threat_level))+geom_boxplot()+
  ggtitle("Exe")

ggplot(data=mal.dist.files.exe, aes(x=threat_level, y=sqrt_total_signatures, fill=threat_level))+geom_boxplot()+
  ggtitle("Exe")

# Total processes not as distinct as compared to using the sqrt value
ggplot(data=mal.dist.files.exe, aes(x=threat_level, y=total_processes, fill=threat_level))+geom_boxplot()+
  ggtitle("Exe")

ggplot(data=mal.dist.files.exe, aes(x=threat_level, y=sqrt_total_processes, fill=threat_level))+geom_boxplot()+
  ggtitle("Exe")

ggplot(data=mal.dist.files.exe, aes(x=threat_level, y=total_network_connections, fill=threat_level))+geom_boxplot()+
  ggtitle("Exe")

# Size not as obvious. Log shows clearer distinction.
ggplot(data=mal.dist.files.exe, aes(x=threat_level, y=size, fill=threat_level))+geom_boxplot() +
  ggtitle("Exe")

ggplot(data=mal.dist.files.exe, aes(x=threat_level, y=size_log, fill=threat_level))+geom_boxplot()+
  ggtitle("Exe")


# Non-EXE
ggplot(data=mal.dist.files.nonexe, aes(x=threat_level, y=total_signatures, fill=threat_level))+geom_boxplot()+
  ggtitle("Non-Exe")

# Sqrt value shows clearer distinction
ggplot(data=mal.dist.files.nonexe, aes(x=threat_level, y=total_processes, fill=threat_level))+geom_boxplot()+
  ggtitle("Non-Exe")

ggplot(data=mal.dist.files.nonexe, aes(x=threat_level, y=sqrt_total_processes, fill=threat_level))+geom_boxplot()+
  ggtitle("Non-Exe")

# Sqrt value shows more distinct pattern
ggplot(data=mal.dist.files.nonexe, aes(x=threat_level, y=total_network_connections, fill=threat_level))+geom_boxplot()+
  ggtitle("Non-Exe")

ggplot(data=mal.dist.files.nonexe, aes(x=threat_level, y=sqrt_total_network_connections, fill=threat_level))+geom_boxplot()+
  ggtitle("Non-Exe")

# Using the log value shows more distinct pattern
ggplot(data=mal.dist.files.nonexe, aes(x=threat_level, y=size, fill=threat_level))+geom_boxplot() +
  ggtitle("Non-Exe")

ggplot(data=mal.dist.files.nonexe, aes(x=threat_level, y=size_log, fill=threat_level))+geom_boxplot() +
  ggtitle("Non-Exe")


# URLs

ggplot(data=mal.dist.urls, aes(x=threat_level, y=total_signatures, fill=threat_level))+geom_boxplot()+
  ggtitle("URL")

ggplot(data=mal.dist.urls, aes(x=threat_level, y=total_processes, fill=threat_level))+geom_boxplot()+
  ggtitle("URL")

ggplot(data=mal.dist.urls, aes(x=threat_level, y=total_network_connections, fill=threat_level))+geom_boxplot()+
  ggtitle("URL")

ggplot(data=mal.dist.urls, aes(x=threat_level, y=sqrt_total_network_connections, fill=threat_level))+geom_boxplot()+
  ggtitle("URL")

str(mal.dist.files.exe)
str(mal.dist.files.nonexe)
str(mal.dist.urls)

# For the EXE file types, the missing values happened in .bss, .data, .idata, .rsrc,
# .tls and .text. These are components within an executable so should be present.
# As such, it would make sense to impute the missing values when building the model
# for EXE files. For the other file types, such imputation may not make sense.

# Method used is pmm for those selected columns only
imp_cols <- c(".bss", ".data", ".idata", ".rsrc",".tls",".text")
imputed_data <- mice(mal.dist.files.exe[imp_cols], m=5, maxit = 50, method = 'pmm', seed = 500)
summary(imputed_data)

# Use set number 3
exe_imputed <- complete(imputed_data,3)

#Update the values into the original df for model building
mal.dist.files.exe[imp_cols] <- exe_imputed

# Check if imputation was successful
mal.dist.files.exe %>% missing_plot()


##################################################################################


# Save the individual segregation for subsequent predictive analytics model
# building
write.csv(mal.dist.urls,"Subset_Distinct_URLs_Transformed.csv", row.names = FALSE)
write.csv(mal.dist.files.exe,"Subset_Distinct_EXE_Transformed.csv", row.names = FALSE)
write.csv(mal.dist.files.nonexe,"Subset_Distinct_NonEXE_Transformed.csv", row.names = FALSE)


#######################

